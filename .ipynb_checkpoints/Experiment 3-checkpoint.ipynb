{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dgl import DGLGraph\n",
    "import dgl.function as fn\n",
    "from functools import partial\n",
    "import dgl\n",
    "from dgl.contrib.data import load_data\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.nn.pytorch import RelGraphConv\n",
    "class BaseRGCN(nn.Module):\n",
    "    def __init__(self, num_nodes, h_dim, out_dim, num_rels, num_bases,\n",
    "                 num_hidden_layers=1, dropout=0,\n",
    "                 use_self_loop=False, use_cuda=False):\n",
    "        super(BaseRGCN, self).__init__()\n",
    "        self.num_nodes = num_nodes\n",
    "        self.h_dim = h_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.num_rels = num_rels\n",
    "        self.num_bases = None if num_bases < 0 else num_bases\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "        self.dropout = dropout\n",
    "        self.use_self_loop = use_self_loop\n",
    "        self.use_cuda = use_cuda\n",
    "\n",
    "        # create rgcn layers\n",
    "        self.build_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        self.layers = nn.ModuleList()\n",
    "        # i2h\n",
    "        i2h = self.build_input_layer()\n",
    "        if i2h is not None:\n",
    "            self.layers.append(i2h)\n",
    "        # h2h\n",
    "        for idx in range(self.num_hidden_layers):\n",
    "            h2h = self.build_hidden_layer(idx)\n",
    "            self.layers.append(h2h)\n",
    "        # h2o\n",
    "        h2o = self.build_output_layer()\n",
    "        if h2o is not None:\n",
    "            self.layers.append(h2o)\n",
    "\n",
    "    def build_input_layer(self):\n",
    "        return None\n",
    "\n",
    "    def build_hidden_layer(self, idx):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def build_output_layer(self):\n",
    "        return None\n",
    "\n",
    "    def forward(self, g, h, r, norm):\n",
    "        for layer in self.layers:\n",
    "            h = layer(g, h, r, norm)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingLayer(nn.Module):\n",
    "    def __init__(self, num_nodes, h_dim):\n",
    "        super(EmbeddingLayer, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, h_dim)\n",
    "\n",
    "    def forward(self, g, h, r, norm):\n",
    "        return self.embedding(h.squeeze())\n",
    "\n",
    "class RGCN(BaseRGCN):\n",
    "    def build_input_layer(self):\n",
    "        return EmbeddingLayer(self.num_nodes, self.h_dim)\n",
    "\n",
    "    def build_hidden_layer(self, idx):\n",
    "        act = F.relu if idx < self.num_hidden_layers - 1 else None\n",
    "        return RelGraphConv(self.h_dim, self.h_dim, self.num_rels, \"bdd\",\n",
    "                self.num_bases, activation=act, self_loop=True,\n",
    "                dropout=self.dropout)\n",
    "\n",
    "class LinkPredict(nn.Module):\n",
    "    def __init__(self, in_dim, h_dim, num_rels, num_bases=-1,\n",
    "                 num_hidden_layers=1, dropout=0, use_cuda=False, reg_param=0):\n",
    "        super(LinkPredict, self).__init__()\n",
    "        self.rgcn = RGCN(in_dim, h_dim, h_dim, num_rels * 2, num_bases,\n",
    "                         num_hidden_layers, dropout, use_cuda)\n",
    "        self.reg_param = reg_param\n",
    "        self.w_relation = nn.Parameter(torch.Tensor(num_rels, h_dim))\n",
    "        nn.init.xavier_uniform_(self.w_relation,\n",
    "                                gain=nn.init.calculate_gain('relu'))\n",
    "\n",
    "    def calc_score(self, embedding, triplets):\n",
    "        # DistMult\n",
    "        s = embedding[triplets[:,0]]\n",
    "        r = self.w_relation[triplets[:,1]]\n",
    "        o = embedding[triplets[:,2]]\n",
    "        score = torch.sum(s * r * o, dim=1)\n",
    "        return score\n",
    "\n",
    "    def forward(self, g, h, r, norm):\n",
    "        return self.rgcn.forward(g, h, r, norm)\n",
    "\n",
    "    def regularization_loss(self, embedding):\n",
    "        return torch.mean(embedding.pow(2)) + torch.mean(self.w_relation.pow(2))\n",
    "\n",
    "    def get_loss(self, g, embed, triplets, labels):\n",
    "        # triplets is a list of data samples (positive and negative)\n",
    "        # each row in the triplets is a 3-tuple of (source, relation, destination)\n",
    "        score = self.calc_score(embed, triplets)\n",
    "        predict_loss = F.binary_cross_entropy_with_logits(score, labels)\n",
    "        reg_loss = self.regularization_loss(embed)\n",
    "        return predict_loss + self.reg_param * reg_loss\n",
    "    def evaluate(self, g):\n",
    "        # get embedding and relation weight without grad\n",
    "        embedding = self.forward(g)\n",
    "        return embedding, self.w_relation\n",
    "\n",
    "def node_norm_to_edge_norm(g, node_norm):\n",
    "    g = g.local_var()\n",
    "    # convert to edge norm\n",
    "    g.ndata['norm'] = node_norm\n",
    "    g.apply_edges(lambda edges : {'norm' : edges.dst['norm']})\n",
    "    return g.edata['norm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('sample_dataset_learnavi.csv', index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = len(data.source_name.append(data.target_name).unique())\n",
    "num_rels = len(data.edge.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 4623)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_rels, num_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinkPredict(num_nodes,\n",
    "                    140,\n",
    "                    num_rels,\n",
    "                    num_bases=140,\n",
    "                    num_hidden_layers=2,\n",
    "                    dropout=0.2,\n",
    "                    use_cuda=-1,\n",
    "                    reg_param=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_data, valid_data = train_test_split(data[['source','edge','target']].values, test_size=0.33, random_state=42)\n",
    "valid_data, test_data = train_test_split(valid_data, test_size=0.5, random_state=42)\n",
    "# data = shuffle(data).reset_index(drop=True)\n",
    "# train_data = data[:6055]\n",
    "# valid_data = data[6055:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data[['source','edge','target']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7569, 3), (1249, 3), (1249, 3))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape, valid_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data = torch.LongTensor(valid_data)\n",
    "test_data = torch.LongTensor(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adj_and_degrees(num_nodes, triplets):\n",
    "    \"\"\" Get adjacency list and degrees of the graph\n",
    "    \"\"\"\n",
    "    adj_list = [[] for _ in range(num_nodes)]\n",
    "    for i,triplet in enumerate(triplets):\n",
    "        adj_list[triplet[0]].append([i, triplet[2]])\n",
    "        adj_list[triplet[2]].append([i, triplet[0]])\n",
    "\n",
    "    degrees = np.array([len(a) for a in adj_list])\n",
    "    adj_list = [np.array(a) for a in adj_list]\n",
    "    return adj_list, degrees\n",
    "\n",
    "def sample_edge_neighborhood(adj_list, degrees, n_triplets, sample_size):\n",
    "    \"\"\"Sample edges by neighborhool expansion.\n",
    "    This guarantees that the sampled edges form a connected graph, which\n",
    "    may help deeper GNNs that require information from more than one hop.\n",
    "    \"\"\"\n",
    "    edges = np.zeros((sample_size), dtype=np.int32)\n",
    "\n",
    "    #initialize\n",
    "    sample_counts = np.array([d for d in degrees])\n",
    "    picked = np.array([False for _ in range(n_triplets)])\n",
    "    seen = np.array([False for _ in degrees])\n",
    "\n",
    "    for i in range(0, sample_size):\n",
    "        weights = sample_counts * seen\n",
    "\n",
    "        if np.sum(weights) == 0:\n",
    "            weights = np.ones_like(weights)\n",
    "            weights[np.where(sample_counts == 0)] = 0\n",
    "\n",
    "        probabilities = (weights) / np.sum(weights)\n",
    "        chosen_vertex = np.random.choice(np.arange(degrees.shape[0]),\n",
    "                                         p=probabilities)\n",
    "        chosen_adj_list = adj_list[chosen_vertex]\n",
    "        seen[chosen_vertex] = True\n",
    "\n",
    "        chosen_edge = np.random.choice(np.arange(chosen_adj_list.shape[0]))\n",
    "        chosen_edge = chosen_adj_list[chosen_edge]\n",
    "        edge_number = chosen_edge[0]\n",
    "\n",
    "        while picked[edge_number]:\n",
    "            chosen_edge = np.random.choice(np.arange(chosen_adj_list.shape[0]))\n",
    "            chosen_edge = chosen_adj_list[chosen_edge]\n",
    "            edge_number = chosen_edge[0]\n",
    "\n",
    "        edges[i] = edge_number\n",
    "        other_vertex = chosen_edge[1]\n",
    "        picked[edge_number] = True\n",
    "        sample_counts[chosen_vertex] -= 1\n",
    "        sample_counts[other_vertex] -= 1\n",
    "        seen[other_vertex] = True\n",
    "\n",
    "    return edges\n",
    "\n",
    "def sample_edge_uniform(adj_list, degrees, n_triplets, sample_size):\n",
    "    \"\"\"Sample edges uniformly from all the edges.\"\"\"\n",
    "    all_edges = np.arange(n_triplets)\n",
    "    return np.random.choice(all_edges, sample_size, replace=False)\n",
    "\n",
    "def generate_sampled_graph_and_labels(triplets, sample_size, split_size,\n",
    "                                      num_rels, adj_list, degrees,\n",
    "                                      negative_rate, sampler=\"uniform\"):\n",
    "    \"\"\"Get training graph and signals\n",
    "    First perform edge neighborhood sampling on graph, then perform negative\n",
    "    sampling to generate negative samples\n",
    "    \"\"\"\n",
    "    # perform edge neighbor sampling\n",
    "    if sampler == \"uniform\":\n",
    "        edges = sample_edge_uniform(adj_list, degrees, len(triplets), sample_size)\n",
    "    elif sampler == \"neighbor\":\n",
    "        edges = sample_edge_neighborhood(adj_list, degrees, len(triplets), sample_size)\n",
    "    else:\n",
    "        raise ValueError(\"Sampler type must be either 'uniform' or 'neighbor'.\")\n",
    "\n",
    "    # relabel nodes to have consecutive node ids\n",
    "    edges = triplets[edges]\n",
    "    src, rel, dst = edges.transpose()\n",
    "    uniq_v, edges = np.unique((src, dst), return_inverse=True)\n",
    "    src, dst = np.reshape(edges, (2, -1))\n",
    "    relabeled_edges = np.stack((src, rel, dst)).transpose()\n",
    "\n",
    "    # negative sampling\n",
    "    samples, labels = negative_sampling(relabeled_edges, len(uniq_v),\n",
    "                                        negative_rate)\n",
    "\n",
    "    # further split graph, only half of the edges will be used as graph\n",
    "    # structure, while the rest half is used as unseen positive samples\n",
    "    split_size = int(sample_size * split_size)\n",
    "    graph_split_ids = np.random.choice(np.arange(sample_size),\n",
    "                                       size=split_size, replace=False)\n",
    "    src = src[graph_split_ids]\n",
    "    dst = dst[graph_split_ids]\n",
    "    rel = rel[graph_split_ids]\n",
    "\n",
    "    # build DGL graph\n",
    "    print(\"# sampled nodes: {}\".format(len(uniq_v)))\n",
    "    print(\"# sampled edges: {}\".format(len(src) * 2))\n",
    "    g, rel, norm = build_graph_from_triplets(len(uniq_v), num_rels,\n",
    "                                             (src, rel, dst))\n",
    "    return g, uniq_v, rel, norm, samples, labels\n",
    "\n",
    "def comp_deg_norm(g):\n",
    "    g = g.local_var()\n",
    "    in_deg = g.in_degrees(range(g.number_of_nodes())).float().numpy()\n",
    "    norm = 1.0 / in_deg\n",
    "    norm[np.isinf(norm)] = 0\n",
    "    return norm\n",
    "\n",
    "def build_graph_from_triplets(num_nodes, num_rels, triplets):\n",
    "    \"\"\" Create a DGL graph. The graph is bidirectional because RGCN authors\n",
    "        use reversed relations.\n",
    "        This function also generates edge type and normalization factor\n",
    "        (reciprocal of node incoming degree)\n",
    "    \"\"\"\n",
    "    g = dgl.DGLGraph()\n",
    "    g.add_nodes(num_nodes)\n",
    "    src, rel, dst = triplets\n",
    "    src, dst = np.concatenate((src, dst)), np.concatenate((dst, src))\n",
    "    rel = np.concatenate((rel, rel + num_rels))\n",
    "    edges = sorted(zip(dst, src, rel))\n",
    "    dst, src, rel = np.array(edges).transpose()\n",
    "    g.add_edges(src, dst)\n",
    "    norm = comp_deg_norm(g)\n",
    "    print(\"# nodes: {}, # edges: {}\".format(num_nodes, len(src)))\n",
    "    return g, rel.astype('int64'), norm.astype('int64')\n",
    "\n",
    "def build_test_graph(num_nodes, num_rels, edges):\n",
    "    src, rel, dst = edges.transpose()\n",
    "    print(\"Test graph:\")\n",
    "    return build_graph_from_triplets(num_nodes, num_rels, (src, rel, dst))\n",
    "\n",
    "def negative_sampling(pos_samples, num_entity, negative_rate):\n",
    "    size_of_batch = len(pos_samples)\n",
    "    num_to_generate = size_of_batch * negative_rate\n",
    "    neg_samples = np.tile(pos_samples, (negative_rate, 1))\n",
    "    labels = np.zeros(size_of_batch * (negative_rate + 1), dtype=np.float32)\n",
    "    labels[: size_of_batch] = 1\n",
    "    values = np.random.randint(num_entity, size=num_to_generate)\n",
    "    choices = np.random.uniform(size=num_to_generate)\n",
    "    subj = choices > 0.5\n",
    "    obj = choices <= 0.5\n",
    "    neg_samples[subj, 0] = values[subj]\n",
    "    neg_samples[obj, 2] = values[obj]\n",
    "\n",
    "    return np.concatenate((pos_samples, neg_samples)), labels\n",
    "\n",
    "#######################################################################\n",
    "#\n",
    "# Utility functions for evaluations (raw)\n",
    "#\n",
    "#######################################################################\n",
    "\n",
    "def sort_and_rank(score, target):\n",
    "    _, indices = torch.sort(score, dim=1, descending=True)\n",
    "    indices = torch.nonzero(indices == target.view(-1, 1))\n",
    "    indices = indices[:, 1].view(-1)\n",
    "    return indices\n",
    "\n",
    "def perturb_and_get_raw_rank(embedding, w, a, r, b, test_size, batch_size=100):\n",
    "    \"\"\" Perturb one element in the triplets\n",
    "    \"\"\"\n",
    "    n_batch = (test_size + batch_size - 1) // batch_size\n",
    "    ranks = []\n",
    "    for idx in range(n_batch):\n",
    "        print(\"batch {} / {}\".format(idx, n_batch))\n",
    "        batch_start = idx * batch_size\n",
    "        batch_end = min(test_size, (idx + 1) * batch_size)\n",
    "        batch_a = a[batch_start: batch_end]\n",
    "        batch_r = r[batch_start: batch_end]\n",
    "        emb_ar = embedding[batch_a] * w[batch_r]\n",
    "        emb_ar = emb_ar.transpose(0, 1).unsqueeze(2) # size: D x E x 1\n",
    "        emb_c = embedding.transpose(0, 1).unsqueeze(1) # size: D x 1 x V\n",
    "        # out-prod and reduce sum\n",
    "        out_prod = torch.bmm(emb_ar, emb_c) # size D x E x V\n",
    "        score = torch.sum(out_prod, dim=0) # size E x V\n",
    "        score = torch.sigmoid(score)\n",
    "        target = b[batch_start: batch_end]\n",
    "        ranks.append(sort_and_rank(score, target))\n",
    "    print(ranks, torch.cat(ranks))\n",
    "    return torch.cat(ranks)\n",
    "\n",
    "# return MRR (raw), and Hits @ (1, 3, 10)\n",
    "def calc_raw_mrr(embedding, w, test_triplets, hits=[], eval_bz=100):\n",
    "    with torch.no_grad():\n",
    "        s = test_triplets[:, 0]\n",
    "        r = test_triplets[:, 1]\n",
    "        o = test_triplets[:, 2]\n",
    "        test_size = test_triplets.shape[0]\n",
    "\n",
    "        # perturb subject\n",
    "        ranks_s = perturb_and_get_raw_rank(embedding, w, o, r, s, test_size, eval_bz)\n",
    "        # perturb object\n",
    "        ranks_o = perturb_and_get_raw_rank(embedding, w, s, r, o, test_size, eval_bz)\n",
    "\n",
    "        ranks = torch.cat([ranks_s, ranks_o])\n",
    "        ranks += 1 # change to 1-indexed\n",
    "        print(ranks)\n",
    "        mrr = torch.mean(1.0 / ranks.float())\n",
    "        print(\"MRR (raw): {:.6f}\".format(mrr.item()))\n",
    "\n",
    "        for hit in hits:\n",
    "            avg_count = torch.mean((ranks <= hit).float())\n",
    "            print(\"Hits (raw) @ {}: {:.6f}\".format(hit, avg_count.item()))\n",
    "    return mrr.item()\n",
    "\n",
    "def filter_o(triplets_to_filter, target_s, target_r, target_o, num_entities):\n",
    "    target_s, target_r, target_o = int(target_s), int(target_r), int(target_o)\n",
    "    filtered_o = []\n",
    "    # Do not filter out the test triplet, since we want to predict on it\n",
    "    if (target_s, target_r, target_o) in triplets_to_filter:\n",
    "        triplets_to_filter.remove((target_s, target_r, target_o))\n",
    "    # Do not consider an object if it is part of a triplet to filter\n",
    "    for o in range(num_entities):\n",
    "        if (target_s, target_r, o) not in triplets_to_filter:\n",
    "            filtered_o.append(o)\n",
    "    return torch.LongTensor(filtered_o)\n",
    "\n",
    "def filter_s(triplets_to_filter, target_s, target_r, target_o, num_entities):\n",
    "    target_s, target_r, target_o = int(target_s), int(target_r), int(target_o)\n",
    "    filtered_s = []\n",
    "    # Do not filter out the test triplet, since we want to predict on it\n",
    "    if (target_s, target_r, target_o) in triplets_to_filter:\n",
    "        triplets_to_filter.remove((target_s, target_r, target_o))\n",
    "    # Do not consider a subject if it is part of a triplet to filter\n",
    "    for s in range(num_entities):\n",
    "        if (s, target_r, target_o) not in triplets_to_filter:\n",
    "            filtered_s.append(s)\n",
    "    return torch.LongTensor(filtered_s)\n",
    "\n",
    "def perturb_o_and_get_filtered_rank(embedding, w, s, r, o, test_size, triplets_to_filter):\n",
    "    \"\"\" Perturb object in the triplets\n",
    "    \"\"\"\n",
    "    num_entities = embedding.shape[0]\n",
    "    ranks = []\n",
    "    for idx in range(test_size):\n",
    "        if idx % 100 == 0:\n",
    "            print(\"test triplet {} / {}\".format(idx, test_size))\n",
    "        target_s = s[idx]\n",
    "        target_r = r[idx]\n",
    "        target_o = o[idx]\n",
    "        filtered_o = filter_o(triplets_to_filter, target_s, target_r, target_o, num_entities)\n",
    "        target_o_idx = int((filtered_o == target_o).nonzero())\n",
    "        emb_s = embedding[target_s]\n",
    "        emb_r = w[target_r]\n",
    "        emb_o = embedding[filtered_o]\n",
    "        emb_triplet = emb_s * emb_r * emb_o\n",
    "        scores = torch.sigmoid(torch.sum(emb_triplet, dim=1))\n",
    "        _, indices = torch.sort(scores, descending=True)\n",
    "        rank = int((indices == target_o_idx).nonzero())\n",
    "        ranks.append(rank)\n",
    "    return torch.LongTensor(ranks)\n",
    "\n",
    "def perturb_s_and_get_filtered_rank(embedding, w, s, r, o, test_size, triplets_to_filter):\n",
    "    \"\"\" Perturb subject in the triplets\n",
    "    \"\"\"\n",
    "    num_entities = embedding.shape[0]\n",
    "    ranks = []\n",
    "    for idx in range(test_size):\n",
    "        if idx % 100 == 0:\n",
    "            print(\"test triplet {} / {}\".format(idx, test_size))\n",
    "        target_s = s[idx]\n",
    "        target_r = r[idx]\n",
    "        target_o = o[idx]\n",
    "        filtered_s = filter_s(triplets_to_filter, target_s, target_r, target_o, num_entities)\n",
    "        target_s_idx = int((filtered_s == target_s).nonzero())\n",
    "        emb_s = embedding[filtered_s]\n",
    "        emb_r = w[target_r]\n",
    "        emb_o = embedding[target_o]\n",
    "        emb_triplet = emb_s * emb_r * emb_o\n",
    "        scores = torch.sigmoid(torch.sum(emb_triplet, dim=1))\n",
    "        _, indices = torch.sort(scores, descending=True)\n",
    "        rank = int((indices == target_s_idx).nonzero())\n",
    "        ranks.append(rank)\n",
    "    return torch.LongTensor(ranks)\n",
    "\n",
    "def calc_filtered_mrr(embedding, w, train_triplets, valid_triplets, test_triplets, hits=[]):\n",
    "    with torch.no_grad():\n",
    "        s = test_triplets[:, 0]\n",
    "        r = test_triplets[:, 1]\n",
    "        o = test_triplets[:, 2]\n",
    "        test_size = test_triplets.shape[0]\n",
    "\n",
    "        triplets_to_filter = torch.cat([train_triplets, valid_triplets, test_triplets]).tolist()\n",
    "        triplets_to_filter = {tuple(triplet) for triplet in triplets_to_filter}\n",
    "        print('Perturbing subject...')\n",
    "        ranks_s = perturb_s_and_get_filtered_rank(embedding, w, s, r, o, test_size, triplets_to_filter)\n",
    "        print('Perturbing object...')\n",
    "        ranks_o = perturb_o_and_get_filtered_rank(embedding, w, s, r, o, test_size, triplets_to_filter)\n",
    "\n",
    "        ranks = torch.cat([ranks_s, ranks_o])\n",
    "        ranks += 1 # change to 1-indexed\n",
    "\n",
    "        mrr = torch.mean(1.0 / ranks.float())\n",
    "        print(\"MRR (filtered): {:.6f}\".format(mrr.item()))\n",
    "\n",
    "        for hit in hits:\n",
    "            avg_count = torch.mean((ranks <= hit).float())\n",
    "            print(\"Hits (filtered) @ {}: {:.6f}\".format(hit, avg_count.item()))\n",
    "    return mrr.item()\n",
    "\n",
    "def calc_mrr(embedding, w, train_triplets, valid_triplets, test_triplets, hits=[], eval_bz=100, eval_p=\"filtered\"):\n",
    "    if eval_p == \"filtered\":\n",
    "        mrr = calc_filtered_mrr(embedding, w, train_triplets, valid_triplets, test_triplets, hits)\n",
    "    else:\n",
    "        mrr = calc_raw_mrr(embedding, w, test_triplets, hits, eval_bz)\n",
    "    return mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test graph:\n",
      "# nodes: 4623, # edges: 15138\n"
     ]
    }
   ],
   "source": [
    "# build test graph\n",
    "test_graph, test_rel, test_norm = build_test_graph(\n",
    "    num_nodes, num_rels, train_data)\n",
    "test_deg = test_graph.in_degrees(range(test_graph.number_of_nodes())).float().view(-1,1)\n",
    "test_node_id = torch.arange(0, num_nodes, dtype=torch.long).view(-1, 1)\n",
    "test_rel = torch.from_numpy(test_rel)\n",
    "test_norm = node_norm_to_edge_norm(test_graph, torch.from_numpy(test_norm).view(-1, 1))\n",
    "# test_graph.ndata.update({'id': test_node_id, 'norm': test_norm})\n",
    "# test_graph.edata['type'] = test_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    " # build adj list and calculate degrees for sampling\n",
    "adj_list, degrees = get_adj_and_degrees(num_nodes, train_data)\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training...\n",
      "# sampled nodes: 34\n",
      "# sampled edges: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Aplikasi\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:106: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# nodes: 34, # edges: 20\n",
      "Done edge sampling\n",
      "Epoch 0001 | Loss 3.2399 | Best MRR 0.0000 | Forward 0.1469s | Backward 0.0907s\n",
      "# sampled nodes: 34\n",
      "# sampled edges: 20\n",
      "# nodes: 34, # edges: 20\n",
      "Done edge sampling\n",
      "Epoch 0002 | Loss 1.4982 | Best MRR 0.0000 | Forward 0.0221s | Backward 0.0536s\n",
      "start eval\n",
      "Perturbing subject...\n",
      "test triplet 0 / 1249\n",
      "test triplet 100 / 1249\n",
      "test triplet 200 / 1249\n",
      "test triplet 300 / 1249\n",
      "test triplet 400 / 1249\n",
      "test triplet 500 / 1249\n",
      "test triplet 600 / 1249\n",
      "test triplet 700 / 1249\n",
      "test triplet 800 / 1249\n",
      "test triplet 900 / 1249\n",
      "test triplet 1000 / 1249\n",
      "test triplet 1100 / 1249\n",
      "test triplet 1200 / 1249\n",
      "Perturbing object...\n",
      "test triplet 0 / 1249\n",
      "test triplet 100 / 1249\n",
      "test triplet 200 / 1249\n",
      "test triplet 300 / 1249\n",
      "test triplet 400 / 1249\n",
      "test triplet 500 / 1249\n",
      "test triplet 600 / 1249\n",
      "test triplet 700 / 1249\n",
      "test triplet 800 / 1249\n",
      "test triplet 900 / 1249\n",
      "test triplet 1000 / 1249\n",
      "test triplet 1100 / 1249\n",
      "test triplet 1200 / 1249\n",
      "MRR (filtered): 0.002905\n",
      "Hits (filtered) @ 1: 0.000400\n",
      "Hits (filtered) @ 3: 0.000801\n",
      "Hits (filtered) @ 10: 0.004404\n",
      "# sampled nodes: 31\n",
      "# sampled edges: 20\n",
      "# nodes: 31, # edges: 20\n",
      "Done edge sampling\n",
      "Epoch 0003 | Loss 1.4046 | Best MRR 0.0029 | Forward 0.0521s | Backward 0.0406s\n",
      "# sampled nodes: 30\n",
      "# sampled edges: 20\n",
      "# nodes: 30, # edges: 20\n",
      "Done edge sampling\n",
      "Epoch 0004 | Loss 1.2026 | Best MRR 0.0029 | Forward 0.0110s | Backward 0.0501s\n",
      "start eval\n",
      "Perturbing subject...\n",
      "test triplet 0 / 1249\n",
      "test triplet 100 / 1249\n",
      "test triplet 200 / 1249\n",
      "test triplet 300 / 1249\n",
      "test triplet 400 / 1249\n",
      "test triplet 500 / 1249\n",
      "test triplet 600 / 1249\n",
      "test triplet 700 / 1249\n",
      "test triplet 800 / 1249\n",
      "test triplet 900 / 1249\n",
      "test triplet 1000 / 1249\n",
      "test triplet 1100 / 1249\n",
      "test triplet 1200 / 1249\n",
      "Perturbing object...\n",
      "test triplet 0 / 1249\n",
      "test triplet 100 / 1249\n",
      "test triplet 200 / 1249\n",
      "test triplet 300 / 1249\n",
      "test triplet 400 / 1249\n",
      "test triplet 500 / 1249\n",
      "test triplet 600 / 1249\n",
      "test triplet 700 / 1249\n",
      "test triplet 800 / 1249\n",
      "test triplet 900 / 1249\n",
      "test triplet 1000 / 1249\n",
      "test triplet 1100 / 1249\n",
      "test triplet 1200 / 1249\n",
      "MRR (filtered): 0.022371\n",
      "Hits (filtered) @ 1: 0.011609\n",
      "Hits (filtered) @ 3: 0.020016\n",
      "Hits (filtered) @ 10: 0.041633\n",
      "# sampled nodes: 30\n",
      "# sampled edges: 20\n",
      "# nodes: 30, # edges: 20\n",
      "Done edge sampling\n",
      "Epoch 0005 | Loss 1.6107 | Best MRR 0.0224 | Forward 0.0572s | Backward 0.0486s\n",
      "# sampled nodes: 31\n",
      "# sampled edges: 20\n",
      "# nodes: 31, # edges: 20\n",
      "Done edge sampling\n",
      "Epoch 0006 | Loss 1.6174 | Best MRR 0.0224 | Forward 0.0175s | Backward 0.0587s\n",
      "start eval\n",
      "Perturbing subject...\n",
      "test triplet 0 / 1249\n",
      "test triplet 100 / 1249\n",
      "test triplet 200 / 1249\n",
      "test triplet 300 / 1249\n",
      "test triplet 400 / 1249\n",
      "test triplet 500 / 1249\n",
      "test triplet 600 / 1249\n",
      "test triplet 700 / 1249\n",
      "test triplet 800 / 1249\n",
      "test triplet 900 / 1249\n",
      "test triplet 1000 / 1249\n",
      "test triplet 1100 / 1249\n",
      "test triplet 1200 / 1249\n",
      "Perturbing object...\n",
      "test triplet 0 / 1249\n",
      "test triplet 100 / 1249\n",
      "test triplet 200 / 1249\n",
      "test triplet 300 / 1249\n",
      "test triplet 400 / 1249\n",
      "test triplet 500 / 1249\n",
      "test triplet 600 / 1249\n",
      "test triplet 700 / 1249\n",
      "test triplet 800 / 1249\n",
      "test triplet 900 / 1249\n",
      "test triplet 1000 / 1249\n",
      "test triplet 1100 / 1249\n",
      "test triplet 1200 / 1249\n",
      "MRR (filtered): 0.103734\n",
      "Hits (filtered) @ 1: 0.082866\n",
      "Hits (filtered) @ 3: 0.106485\n",
      "Hits (filtered) @ 10: 0.142914\n",
      "# sampled nodes: 29\n",
      "# sampled edges: 20\n",
      "# nodes: 29, # edges: 20\n",
      "Done edge sampling\n",
      "Epoch 0007 | Loss 1.6991 | Best MRR 0.1037 | Forward 0.0662s | Backward 0.0461s\n",
      "# sampled nodes: 32\n",
      "# sampled edges: 20\n",
      "# nodes: 32, # edges: 20\n",
      "Done edge sampling\n",
      "Epoch 0008 | Loss 1.1873 | Best MRR 0.1037 | Forward 0.0170s | Backward 0.0511s\n",
      "start eval\n",
      "Perturbing subject...\n",
      "test triplet 0 / 1249\n",
      "test triplet 100 / 1249\n",
      "test triplet 200 / 1249\n",
      "test triplet 300 / 1249\n",
      "test triplet 400 / 1249\n",
      "test triplet 500 / 1249\n",
      "test triplet 600 / 1249\n",
      "test triplet 700 / 1249\n",
      "test triplet 800 / 1249\n",
      "test triplet 900 / 1249\n",
      "test triplet 1000 / 1249\n",
      "test triplet 1100 / 1249\n",
      "test triplet 1200 / 1249\n",
      "Perturbing object...\n",
      "test triplet 0 / 1249\n",
      "test triplet 100 / 1249\n",
      "test triplet 200 / 1249\n",
      "test triplet 300 / 1249\n",
      "test triplet 400 / 1249\n",
      "test triplet 500 / 1249\n",
      "test triplet 600 / 1249\n",
      "test triplet 700 / 1249\n",
      "test triplet 800 / 1249\n",
      "test triplet 900 / 1249\n",
      "test triplet 1000 / 1249\n",
      "test triplet 1100 / 1249\n",
      "test triplet 1200 / 1249\n",
      "MRR (filtered): 0.041720\n",
      "Hits (filtered) @ 1: 0.015612\n",
      "Hits (filtered) @ 3: 0.053643\n",
      "Hits (filtered) @ 10: 0.076861\n",
      "# sampled nodes: 27\n",
      "# sampled edges: 20\n",
      "# nodes: 27, # edges: 20\n",
      "Done edge sampling\n",
      "Epoch 0009 | Loss 0.9751 | Best MRR 0.1037 | Forward 0.0679s | Backward 0.0456s\n",
      "# sampled nodes: 30\n",
      "# sampled edges: 20\n",
      "# nodes: 30, # edges: 20\n",
      "Done edge sampling\n",
      "Epoch 0010 | Loss 1.2217 | Best MRR 0.1037 | Forward 0.0201s | Backward 0.0727s\n",
      "start eval\n",
      "Perturbing subject...\n",
      "test triplet 0 / 1249\n",
      "test triplet 100 / 1249\n",
      "test triplet 200 / 1249\n",
      "test triplet 300 / 1249\n",
      "test triplet 400 / 1249\n",
      "test triplet 500 / 1249\n",
      "test triplet 600 / 1249\n",
      "test triplet 700 / 1249\n",
      "test triplet 800 / 1249\n",
      "test triplet 900 / 1249\n",
      "test triplet 1000 / 1249\n",
      "test triplet 1100 / 1249\n",
      "test triplet 1200 / 1249\n",
      "Perturbing object...\n",
      "test triplet 0 / 1249\n",
      "test triplet 100 / 1249\n",
      "test triplet 200 / 1249\n",
      "test triplet 300 / 1249\n",
      "test triplet 400 / 1249\n",
      "test triplet 500 / 1249\n",
      "test triplet 600 / 1249\n",
      "test triplet 700 / 1249\n",
      "test triplet 800 / 1249\n",
      "test triplet 900 / 1249\n",
      "test triplet 1000 / 1249\n",
      "test triplet 1100 / 1249\n",
      "test triplet 1200 / 1249\n",
      "MRR (filtered): 0.038528\n",
      "Hits (filtered) @ 1: 0.008807\n",
      "Hits (filtered) @ 3: 0.051241\n",
      "Hits (filtered) @ 10: 0.093675\n",
      "# sampled nodes: 28\n",
      "# sampled edges: 20\n",
      "# nodes: 28, # edges: 20\n",
      "Done edge sampling\n",
      "Epoch 0011 | Loss 1.0776 | Best MRR 0.1037 | Forward 0.0717s | Backward 0.0556s\n",
      "# sampled nodes: 29\n",
      "# sampled edges: 20\n",
      "# nodes: 29, # edges: 20\n",
      "Done edge sampling\n",
      "Epoch 0012 | Loss 1.0474 | Best MRR 0.1037 | Forward 0.0140s | Backward 0.0536s\n",
      "start eval\n",
      "Perturbing subject...\n",
      "test triplet 0 / 1249\n",
      "test triplet 100 / 1249\n",
      "test triplet 200 / 1249\n",
      "test triplet 300 / 1249\n",
      "test triplet 400 / 1249\n",
      "test triplet 500 / 1249\n",
      "test triplet 600 / 1249\n",
      "test triplet 700 / 1249\n",
      "test triplet 800 / 1249\n",
      "test triplet 900 / 1249\n",
      "test triplet 1000 / 1249\n",
      "test triplet 1100 / 1249\n",
      "test triplet 1200 / 1249\n",
      "Perturbing object...\n",
      "test triplet 0 / 1249\n",
      "test triplet 100 / 1249\n",
      "test triplet 200 / 1249\n",
      "test triplet 300 / 1249\n",
      "test triplet 400 / 1249\n",
      "test triplet 500 / 1249\n",
      "test triplet 600 / 1249\n",
      "test triplet 700 / 1249\n",
      "test triplet 800 / 1249\n",
      "test triplet 900 / 1249\n",
      "test triplet 1000 / 1249\n",
      "test triplet 1100 / 1249\n",
      "test triplet 1200 / 1249\n",
      "MRR (filtered): 0.172692\n",
      "Hits (filtered) @ 1: 0.138911\n",
      "Hits (filtered) @ 3: 0.191353\n",
      "Hits (filtered) @ 10: 0.230584\n",
      "# sampled nodes: 34\n",
      "# sampled edges: 20\n",
      "# nodes: 34, # edges: 20\n",
      "Done edge sampling\n",
      "Epoch 0013 | Loss 1.2329 | Best MRR 0.1727 | Forward 0.1715s | Backward 0.1063s\n",
      "# sampled nodes: 34\n",
      "# sampled edges: 20\n",
      "# nodes: 34, # edges: 20\n",
      "Done edge sampling\n",
      "Epoch 0014 | Loss 0.9955 | Best MRR 0.1727 | Forward 0.0396s | Backward 0.0772s\n",
      "start eval\n",
      "Perturbing subject...\n",
      "test triplet 0 / 1249\n",
      "test triplet 100 / 1249\n",
      "test triplet 200 / 1249\n",
      "test triplet 300 / 1249\n",
      "test triplet 400 / 1249\n",
      "test triplet 500 / 1249\n",
      "test triplet 600 / 1249\n",
      "test triplet 700 / 1249\n",
      "test triplet 800 / 1249\n",
      "test triplet 900 / 1249\n",
      "test triplet 1000 / 1249\n",
      "test triplet 1100 / 1249\n",
      "test triplet 1200 / 1249\n",
      "Perturbing object...\n",
      "test triplet 0 / 1249\n",
      "test triplet 100 / 1249\n",
      "test triplet 200 / 1249\n",
      "test triplet 300 / 1249\n",
      "test triplet 400 / 1249\n",
      "test triplet 500 / 1249\n",
      "test triplet 600 / 1249\n",
      "test triplet 700 / 1249\n",
      "test triplet 800 / 1249\n",
      "test triplet 900 / 1249\n",
      "test triplet 1000 / 1249\n",
      "test triplet 1100 / 1249\n",
      "test triplet 1200 / 1249\n",
      "MRR (filtered): 0.217062\n",
      "Hits (filtered) @ 1: 0.199760\n",
      "Hits (filtered) @ 3: 0.229784\n",
      "Hits (filtered) @ 10: 0.246197\n",
      "# sampled nodes: 29\n",
      "# sampled edges: 20\n",
      "# nodes: 29, # edges: 20\n",
      "Done edge sampling\n",
      "Epoch 0015 | Loss 0.8168 | Best MRR 0.2171 | Forward 0.0617s | Backward 0.0551s\n",
      "# sampled nodes: 34\n",
      "# sampled edges: 20\n",
      "# nodes: 34, # edges: 20\n",
      "Done edge sampling\n",
      "Epoch 0016 | Loss 1.0575 | Best MRR 0.2171 | Forward 0.0165s | Backward 0.0561s\n",
      "start eval\n",
      "Perturbing subject...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test triplet 0 / 1249\n",
      "test triplet 100 / 1249\n",
      "test triplet 200 / 1249\n",
      "test triplet 300 / 1249\n",
      "test triplet 400 / 1249\n",
      "test triplet 500 / 1249\n",
      "test triplet 600 / 1249\n",
      "test triplet 700 / 1249\n",
      "test triplet 800 / 1249\n",
      "test triplet 900 / 1249\n",
      "test triplet 1000 / 1249\n",
      "test triplet 1100 / 1249\n",
      "test triplet 1200 / 1249\n",
      "Perturbing object...\n",
      "test triplet 0 / 1249\n",
      "test triplet 100 / 1249\n",
      "test triplet 200 / 1249\n",
      "test triplet 300 / 1249\n",
      "test triplet 400 / 1249\n",
      "test triplet 500 / 1249\n",
      "test triplet 600 / 1249\n",
      "test triplet 700 / 1249\n",
      "test triplet 800 / 1249\n",
      "test triplet 900 / 1249\n",
      "test triplet 1000 / 1249\n",
      "test triplet 1100 / 1249\n",
      "test triplet 1200 / 1249\n",
      "MRR (filtered): 0.209623\n",
      "Hits (filtered) @ 1: 0.185348\n",
      "Hits (filtered) @ 3: 0.224980\n",
      "Hits (filtered) @ 10: 0.247798\n",
      "# sampled nodes: 27\n",
      "# sampled edges: 20\n",
      "# nodes: 27, # edges: 20\n",
      "Done edge sampling\n",
      "Epoch 0017 | Loss 0.6592 | Best MRR 0.2171 | Forward 0.0518s | Backward 0.0426s\n",
      "# sampled nodes: 34\n",
      "# sampled edges: 20\n",
      "# nodes: 34, # edges: 20\n",
      "Done edge sampling\n",
      "Epoch 0018 | Loss 0.9198 | Best MRR 0.2171 | Forward 0.0140s | Backward 0.0436s\n",
      "start eval\n",
      "Perturbing subject...\n",
      "test triplet 0 / 1249\n",
      "test triplet 100 / 1249\n",
      "test triplet 200 / 1249\n",
      "test triplet 300 / 1249\n",
      "test triplet 400 / 1249\n",
      "test triplet 500 / 1249\n",
      "test triplet 600 / 1249\n",
      "test triplet 700 / 1249\n",
      "test triplet 800 / 1249\n",
      "test triplet 900 / 1249\n",
      "test triplet 1000 / 1249\n",
      "test triplet 1100 / 1249\n",
      "test triplet 1200 / 1249\n",
      "Perturbing object...\n",
      "test triplet 0 / 1249\n",
      "test triplet 100 / 1249\n",
      "test triplet 200 / 1249\n",
      "test triplet 300 / 1249\n",
      "test triplet 400 / 1249\n",
      "test triplet 500 / 1249\n",
      "test triplet 600 / 1249\n",
      "test triplet 700 / 1249\n",
      "test triplet 800 / 1249\n",
      "test triplet 900 / 1249\n",
      "test triplet 1000 / 1249\n",
      "test triplet 1100 / 1249\n",
      "test triplet 1200 / 1249\n",
      "MRR (filtered): 0.203528\n",
      "Hits (filtered) @ 1: 0.176541\n",
      "Hits (filtered) @ 3: 0.222578\n",
      "Hits (filtered) @ 10: 0.248999\n",
      "# sampled nodes: 31\n",
      "# sampled edges: 20\n",
      "# nodes: 31, # edges: 20\n",
      "Done edge sampling\n",
      "Epoch 0019 | Loss 1.1995 | Best MRR 0.2171 | Forward 0.1083s | Backward 0.0436s\n",
      "# sampled nodes: 34\n",
      "# sampled edges: 20\n",
      "# nodes: 34, # edges: 20\n",
      "Done edge sampling\n",
      "Epoch 0020 | Loss 0.7844 | Best MRR 0.2171 | Forward 0.0185s | Backward 0.0973s\n",
      "start eval\n",
      "Perturbing subject...\n",
      "test triplet 0 / 1249\n",
      "test triplet 100 / 1249\n",
      "test triplet 200 / 1249\n",
      "test triplet 300 / 1249\n",
      "test triplet 400 / 1249\n",
      "test triplet 500 / 1249\n",
      "test triplet 600 / 1249\n",
      "test triplet 700 / 1249\n",
      "test triplet 800 / 1249\n",
      "test triplet 900 / 1249\n",
      "test triplet 1000 / 1249\n",
      "test triplet 1100 / 1249\n",
      "test triplet 1200 / 1249\n",
      "Perturbing object...\n",
      "test triplet 0 / 1249\n",
      "test triplet 100 / 1249\n",
      "test triplet 200 / 1249\n",
      "test triplet 300 / 1249\n",
      "test triplet 400 / 1249\n",
      "test triplet 500 / 1249\n",
      "test triplet 600 / 1249\n",
      "test triplet 700 / 1249\n",
      "test triplet 800 / 1249\n",
      "test triplet 900 / 1249\n",
      "test triplet 1000 / 1249\n",
      "test triplet 1100 / 1249\n",
      "test triplet 1200 / 1249\n",
      "MRR (filtered): 0.193677\n",
      "Hits (filtered) @ 1: 0.165733\n",
      "Hits (filtered) @ 3: 0.204564\n",
      "Hits (filtered) @ 10: 0.244996\n",
      "# sampled nodes: 30\n",
      "# sampled edges: 20\n",
      "# nodes: 30, # edges: 20\n",
      "Done edge sampling\n",
      "Epoch 0021 | Loss 1.2519 | Best MRR 0.2171 | Forward 0.0486s | Backward 0.0416s\n",
      "# sampled nodes: 29\n",
      "# sampled edges: 20\n",
      "# nodes: 29, # edges: 20\n",
      "Done edge sampling\n",
      "Epoch 0022 | Loss 0.6625 | Best MRR 0.2171 | Forward 0.0115s | Backward 0.0421s\n",
      "start eval\n",
      "Perturbing subject...\n",
      "test triplet 0 / 1249\n",
      "test triplet 100 / 1249\n",
      "test triplet 200 / 1249\n",
      "test triplet 300 / 1249\n",
      "test triplet 400 / 1249\n",
      "test triplet 500 / 1249\n",
      "test triplet 600 / 1249\n",
      "test triplet 700 / 1249\n",
      "test triplet 800 / 1249\n",
      "test triplet 900 / 1249\n",
      "test triplet 1000 / 1249\n",
      "test triplet 1100 / 1249\n",
      "test triplet 1200 / 1249\n",
      "Perturbing object...\n",
      "test triplet 0 / 1249\n",
      "test triplet 100 / 1249\n",
      "test triplet 200 / 1249\n",
      "test triplet 300 / 1249\n",
      "test triplet 400 / 1249\n",
      "test triplet 500 / 1249\n",
      "test triplet 600 / 1249\n",
      "test triplet 700 / 1249\n",
      "test triplet 800 / 1249\n",
      "test triplet 900 / 1249\n",
      "test triplet 1000 / 1249\n",
      "test triplet 1100 / 1249\n",
      "test triplet 1200 / 1249\n",
      "MRR (filtered): 0.180322\n",
      "Hits (filtered) @ 1: 0.151321\n",
      "Hits (filtered) @ 3: 0.190552\n",
      "Hits (filtered) @ 10: 0.234588\n",
      "# sampled nodes: 30\n",
      "# sampled edges: 20\n",
      "# nodes: 30, # edges: 20\n",
      "Done edge sampling\n",
      "Epoch 0023 | Loss 1.0056 | Best MRR 0.2171 | Forward 0.0556s | Backward 0.0496s\n",
      "# sampled nodes: 32\n",
      "# sampled edges: 20\n",
      "# nodes: 32, # edges: 20\n",
      "Done edge sampling\n",
      "Epoch 0024 | Loss 0.7454 | Best MRR 0.2171 | Forward 0.0090s | Backward 0.0546s\n",
      "start eval\n",
      "Perturbing subject...\n",
      "test triplet 0 / 1249\n",
      "test triplet 100 / 1249\n",
      "test triplet 200 / 1249\n",
      "test triplet 300 / 1249\n",
      "test triplet 400 / 1249\n",
      "test triplet 500 / 1249\n",
      "test triplet 600 / 1249\n",
      "test triplet 700 / 1249\n",
      "test triplet 800 / 1249\n",
      "test triplet 900 / 1249\n",
      "test triplet 1000 / 1249\n",
      "test triplet 1100 / 1249\n",
      "test triplet 1200 / 1249\n",
      "Perturbing object...\n",
      "test triplet 0 / 1249\n",
      "test triplet 100 / 1249\n",
      "test triplet 200 / 1249\n",
      "test triplet 300 / 1249\n",
      "test triplet 400 / 1249\n",
      "test triplet 500 / 1249\n",
      "test triplet 600 / 1249\n",
      "test triplet 700 / 1249\n",
      "test triplet 800 / 1249\n",
      "test triplet 900 / 1249\n",
      "test triplet 1000 / 1249\n",
      "test triplet 1100 / 1249\n",
      "test triplet 1200 / 1249\n",
      "MRR (filtered): 0.185293\n",
      "Hits (filtered) @ 1: 0.161329\n",
      "Hits (filtered) @ 3: 0.194155\n",
      "Hits (filtered) @ 10: 0.225380\n",
      "# sampled nodes: 28\n",
      "# sampled edges: 20\n",
      "# nodes: 28, # edges: 20\n",
      "Done edge sampling\n",
      "Epoch 0025 | Loss 0.5633 | Best MRR 0.2171 | Forward 0.0506s | Backward 0.0572s\n",
      "# sampled nodes: 31\n",
      "# sampled edges: 20\n",
      "# nodes: 31, # edges: 20\n",
      "Done edge sampling\n",
      "Epoch 0026 | Loss 0.8248 | Best MRR 0.2171 | Forward 0.0125s | Backward 0.0707s\n",
      "start eval\n",
      "Perturbing subject...\n",
      "test triplet 0 / 1249\n",
      "test triplet 100 / 1249\n",
      "test triplet 200 / 1249\n",
      "test triplet 300 / 1249\n",
      "test triplet 400 / 1249\n",
      "test triplet 500 / 1249\n",
      "test triplet 600 / 1249\n",
      "test triplet 700 / 1249\n",
      "test triplet 800 / 1249\n",
      "test triplet 900 / 1249\n",
      "test triplet 1000 / 1249\n",
      "test triplet 1100 / 1249\n",
      "test triplet 1200 / 1249\n",
      "Perturbing object...\n",
      "test triplet 0 / 1249\n",
      "test triplet 100 / 1249\n",
      "test triplet 200 / 1249\n",
      "test triplet 300 / 1249\n",
      "test triplet 400 / 1249\n",
      "test triplet 500 / 1249\n",
      "test triplet 600 / 1249\n",
      "test triplet 700 / 1249\n",
      "test triplet 800 / 1249\n",
      "test triplet 900 / 1249\n",
      "test triplet 1000 / 1249\n",
      "test triplet 1100 / 1249\n",
      "test triplet 1200 / 1249\n",
      "MRR (filtered): 0.188287\n",
      "Hits (filtered) @ 1: 0.162930\n",
      "Hits (filtered) @ 3: 0.195757\n",
      "Hits (filtered) @ 10: 0.239792\n",
      "# sampled nodes: 30\n",
      "# sampled edges: 20\n",
      "# nodes: 30, # edges: 20\n",
      "Done edge sampling\n",
      "Epoch 0027 | Loss 0.7259 | Best MRR 0.2171 | Forward 0.0496s | Backward 0.0416s\n",
      "# sampled nodes: 30\n",
      "# sampled edges: 20\n",
      "# nodes: 30, # edges: 20\n",
      "Done edge sampling\n",
      "Epoch 0028 | Loss 0.8487 | Best MRR 0.2171 | Forward 0.0095s | Backward 0.0431s\n",
      "start eval\n",
      "Perturbing subject...\n",
      "test triplet 0 / 1249\n",
      "test triplet 100 / 1249\n",
      "test triplet 200 / 1249\n",
      "test triplet 300 / 1249\n",
      "test triplet 400 / 1249\n",
      "test triplet 500 / 1249\n",
      "test triplet 600 / 1249\n",
      "test triplet 700 / 1249\n",
      "test triplet 800 / 1249\n",
      "test triplet 900 / 1249\n",
      "test triplet 1000 / 1249\n",
      "test triplet 1100 / 1249\n",
      "test triplet 1200 / 1249\n",
      "Perturbing object...\n",
      "test triplet 0 / 1249\n",
      "test triplet 100 / 1249\n",
      "test triplet 200 / 1249\n",
      "test triplet 300 / 1249\n",
      "test triplet 400 / 1249\n",
      "test triplet 500 / 1249\n",
      "test triplet 600 / 1249\n",
      "test triplet 700 / 1249\n",
      "test triplet 800 / 1249\n",
      "test triplet 900 / 1249\n",
      "test triplet 1000 / 1249\n",
      "test triplet 1100 / 1249\n",
      "test triplet 1200 / 1249\n",
      "MRR (filtered): 0.171896\n",
      "Hits (filtered) @ 1: 0.138911\n",
      "Hits (filtered) @ 3: 0.186950\n",
      "Hits (filtered) @ 10: 0.238191\n",
      "# sampled nodes: 29\n",
      "# sampled edges: 20\n",
      "# nodes: 29, # edges: 20\n",
      "Done edge sampling\n",
      "Epoch 0029 | Loss 0.5902 | Best MRR 0.2171 | Forward 0.0546s | Backward 0.0416s\n",
      "# sampled nodes: 28\n",
      "# sampled edges: 20\n",
      "# nodes: 28, # edges: 20\n",
      "Done edge sampling\n",
      "Epoch 0030 | Loss 0.6460 | Best MRR 0.2171 | Forward 0.0150s | Backward 0.0451s\n",
      "start eval\n",
      "Perturbing subject...\n",
      "test triplet 0 / 1249\n",
      "test triplet 100 / 1249\n",
      "test triplet 200 / 1249\n",
      "test triplet 300 / 1249\n",
      "test triplet 400 / 1249\n",
      "test triplet 500 / 1249\n",
      "test triplet 600 / 1249\n",
      "test triplet 700 / 1249\n",
      "test triplet 800 / 1249\n",
      "test triplet 900 / 1249\n",
      "test triplet 1000 / 1249\n",
      "test triplet 1100 / 1249\n",
      "test triplet 1200 / 1249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perturbing object...\n",
      "test triplet 0 / 1249\n",
      "test triplet 100 / 1249\n",
      "test triplet 200 / 1249\n",
      "test triplet 300 / 1249\n",
      "test triplet 400 / 1249\n",
      "test triplet 500 / 1249\n",
      "test triplet 600 / 1249\n",
      "test triplet 700 / 1249\n",
      "test triplet 800 / 1249\n",
      "test triplet 900 / 1249\n",
      "test triplet 1000 / 1249\n",
      "test triplet 1100 / 1249\n",
      "test triplet 1200 / 1249\n",
      "MRR (filtered): 0.163005\n",
      "Hits (filtered) @ 1: 0.130104\n",
      "Hits (filtered) @ 3: 0.173339\n",
      "Hits (filtered) @ 10: 0.221777\n",
      "training done\n",
      "Mean forward time: 0.045414s\n",
      "Mean Backward time: 0.055883s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "model_state_file = 'model_state.pth'\n",
    "forward_time = []\n",
    "backward_time = []\n",
    "use_cuda=False\n",
    "# training loop\n",
    "print(\"start training...\")\n",
    "\n",
    "epoch = 0\n",
    "best_mrr = 0\n",
    "while True:\n",
    "    model.train()\n",
    "    epoch += 1\n",
    "\n",
    "    # perform edge neighborhood sampling to generate training graph and data\n",
    "    g, node_id, edge_type, node_norm, data, labels = \\\n",
    "        generate_sampled_graph_and_labels(\n",
    "            train_data, 20, 0.5,\n",
    "            num_rels, adj_list, degrees, 10,\n",
    "            'uniform')\n",
    "    print(\"Done edge sampling\")\n",
    "\n",
    "        # set node/edge feature\n",
    "    node_id = torch.from_numpy(node_id).view(-1, 1).long()\n",
    "    edge_type = torch.from_numpy(edge_type)\n",
    "    edge_norm = node_norm_to_edge_norm(g, torch.from_numpy(node_norm).view(-1, 1))\n",
    "    data, labels = torch.from_numpy(data), torch.from_numpy(labels)\n",
    "    deg = g.in_degrees(range(g.number_of_nodes())).float().view(-1, 1)\n",
    "    if use_cuda:\n",
    "        node_id, deg = node_id.cuda(), deg.cuda()\n",
    "        edge_type, edge_norm = edge_type.cuda(), edge_norm.cuda()\n",
    "        data, labels = data.cuda(), labels.cuda()\n",
    "\n",
    "    t0 = time.time()\n",
    "    embed = model(g, node_id, edge_type, edge_norm)\n",
    "    loss = model.get_loss(g, embed, data, labels)\n",
    "    t1 = time.time()\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0) # clip gradients\n",
    "    optimizer.step()\n",
    "    t2 = time.time()\n",
    "\n",
    "    forward_time.append(t1 - t0)\n",
    "    backward_time.append(t2 - t1)\n",
    "    print(\"Epoch {:04d} | Loss {:.4f} | Best MRR {:.4f} | Forward {:.4f}s | Backward {:.4f}s\".\n",
    "            format(epoch, loss.item(), best_mrr, forward_time[-1], backward_time[-1]))\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "        # validation\n",
    "    if epoch % 2 == 0:\n",
    "        # perform validation on CPU because full graph is too large\n",
    "        if use_cuda:\n",
    "            model.cpu()\n",
    "        model.eval()\n",
    "        print(\"start eval\")\n",
    "        embed = model(test_graph, test_node_id, test_rel, test_norm)\n",
    "        mrr = calc_mrr(embed, model.w_relation, torch.LongTensor(train_data),\n",
    "                                valid_data, test_data, hits=[1, 3, 10], eval_bz=500,\n",
    "                                eval_p='filtered')\n",
    "        # save best model\n",
    "        if mrr < best_mrr:\n",
    "            if epoch >= 30:\n",
    "                break\n",
    "        else:\n",
    "            best_mrr = mrr\n",
    "            torch.save({'state_dict': model.state_dict(), 'epoch': epoch},\n",
    "                        model_state_file)\n",
    "        if use_cuda:\n",
    "            model.cuda()\n",
    "\n",
    "print(\"training done\")\n",
    "print(\"Mean forward time: {:4f}s\".format(np.mean(forward_time)))\n",
    "print(\"Mean Backward time: {:4f}s\".format(np.mean(backward_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4623, 1])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_node_id.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = torch.load('model_state.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinkPredict(num_nodes,\n",
    "                                 140,\n",
    "                                 num_rels,\n",
    "                                 num_bases=140,\n",
    "                                 num_hidden_layers=2,\n",
    "                                 dropout=0.2,\n",
    "                                 use_cuda=-1,\n",
    "                                 reg_param=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(state['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "coba = 2\n",
    "coba = torch.LongTensor([coba]).view(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = model(test_graph, test_node_id, test_rel, test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "coba = torch.LongTensor([882,    6, 4622]).view(-1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4622,    3, 3653],\n",
       "       [4622,    3, 3765],\n",
       "       [4622,    3, 3844],\n",
       "       ...,\n",
       "       [1432,    4, 2437],\n",
       "       [1432,    4, 1838],\n",
       "       [1513,    4, 2397]], dtype=int64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0 / 13\n",
      "batch 1 / 13\n",
      "batch 2 / 13\n",
      "batch 3 / 13\n",
      "batch 4 / 13\n",
      "batch 5 / 13\n",
      "batch 6 / 13\n",
      "batch 7 / 13\n",
      "batch 8 / 13\n",
      "batch 9 / 13\n",
      "batch 10 / 13\n",
      "batch 11 / 13\n",
      "batch 12 / 13\n",
      "[tensor([  90,   32, 2389,  104, 3673, 1866, 1825,   56,   50,  611, 2387, 3832,\n",
      "          62,   12,    1, 3529,    0,  660,  141, 3560,   13,   10,    4,   37,\n",
      "        1552,    3, 3088, 3669, 2892, 3327,  141, 2484,   13, 3307,   13, 4169,\n",
      "        2570, 2393,   52, 1909, 2148, 2158,  107,   13, 4465,  193, 1774, 3502,\n",
      "           2,   28, 4014, 4168,   24,    6, 3050,    6, 3401,   13, 2085, 3452,\n",
      "          61,   75, 2191, 4410,   30,   13,   54, 2268,   36, 2563, 4446,   13,\n",
      "        1933, 1198,  115, 4553,   13, 2284, 4094,    5, 2420, 2231, 1566,   95,\n",
      "          61, 3911,  603,   51,    4, 1845,  762, 2412,   67,    4, 2346, 1343,\n",
      "        4323,   14,  402,   29]), tensor([3633, 1853,  733, 4217,  445, 3897, 2865, 3666, 2938,  470, 2533, 3579,\n",
      "        3062,   11,  119, 1734, 3295,  676, 1338,  119, 1319, 1623,  796, 3325,\n",
      "          16,   90,  455, 2858,   99,  723, 4590,  223,   52,  119,   10, 1291,\n",
      "        4168, 1939,  617,   24, 3579, 3467,  809,  503, 2469,   10, 2279, 2151,\n",
      "         701,   84, 3835,  402, 3000, 1103,  173,   63,  422,  405,  900,   32,\n",
      "        3116,   13, 2677,   90,   84,    0,  485, 1814,   57,  501, 2742, 2384,\n",
      "        1200,  432, 2395,   13, 1108, 3866,   56, 2810,   11, 2945, 3678, 4061,\n",
      "        3288,  119, 3766,   16,    1, 2364,   13,   10, 3548, 4112,  539, 1060,\n",
      "        2944, 3505, 3529, 2003]), tensor([ 977,   16, 1579,   32, 2165, 1434, 3877, 3898,   10, 1892, 1414, 3066,\n",
      "          29,  908,  840,   95,  719,   16,    8, 2761,  752,   54,  193,    5,\n",
      "          59, 4107, 3467,    0,  142,   13, 1493, 1859, 3464, 2713, 4405, 2008,\n",
      "        4107, 4384, 1622, 3654,    1,   13, 3494,  180, 3333, 3142,  617, 2823,\n",
      "        3791,  413, 1713, 3740,    1,   13, 1166, 3003,   37, 1259, 2565, 3837,\n",
      "           1, 2687,   13,    9, 1895,    1,   29, 1634, 1190,   28, 3876,    6,\n",
      "          10, 3440,  414, 3337,   58, 1295, 1173, 2241,    5,   54, 3393,  743,\n",
      "          95, 1162, 4032,   94, 4616,  216,   84, 2960,  936,   10,   15,  115,\n",
      "        3803, 1886,  997, 1715]), tensor([  63,  193,   13,  366,    9,   51, 1205,   13,   13,    4, 1560,   14,\n",
      "        4463,  141,   32,  142,   10, 2568,  627,  217, 3973,   54, 3777,    0,\n",
      "        2572, 4230, 3653, 1258, 2894,  264,    9, 1099, 4064, 1268,  864, 1230,\n",
      "          13,   56, 1892, 4142, 1113,  514, 3923, 3049, 1778,    3, 1581, 1583,\n",
      "          52, 1249, 3429, 1773,    4,    5,  142,   54,   16, 4377, 1531, 4175,\n",
      "          10, 4476, 4404, 2314, 3911, 3781, 3731,  146, 2344,   13, 2480,   40,\n",
      "        1701, 3080,  526,   84, 3148,    4,    5,   54, 2119, 1010, 2014, 2984,\n",
      "          55,   24, 3347, 4612,  503, 2567,   59,    1, 1597,    6, 1453,   38,\n",
      "        2086,   32, 3835, 4341]), tensor([  40, 3550,   13,   32,   13,  892,  617,    4,   63, 2514, 2964,  141,\n",
      "           5, 2645,   10, 4326, 1326,    1, 2251, 3489,  293, 1543, 4464,  142,\n",
      "        2630, 3288,  115,  142, 1347, 1454,   13, 3954, 3941,   10,  929, 2812,\n",
      "        3071,   95, 3532, 2778, 1523,    3,   13,  395,  987,   13, 1298,   30,\n",
      "          17,   38, 3037,   59, 1264, 4510,   55, 2256,  343,   59, 1884, 1531,\n",
      "        2446,   30, 3623,   10,   13, 3853,  603,    2, 3331,   11,    5,    1,\n",
      "        1139, 3819,   16,    5,   11,    0, 1801, 3345, 2074,  852, 4480, 1461,\n",
      "          11, 3234,   10, 4243,   60, 2391,    6,   28, 2629,  216, 2721,  329,\n",
      "        2830, 3711,  310,   13]), tensor([1015,  587,   16,  422,  539,    4,    6, 2707,    3,   13, 1299,   55,\n",
      "        1787,    4,  539,   52,   50,  936,   10, 3192,  941,  931,    4,  571,\n",
      "        3014, 1909,   28,   11,   30,   59,    1, 2000, 2526,  209, 1709, 2079,\n",
      "           1, 4211, 1385,   30,    4, 2408,   53, 2406, 3838, 3763,   51, 2677,\n",
      "         126,  742,    9,  816,  427,  216,  216,  115, 4557, 3807, 3791, 1560,\n",
      "        3279,   76,  879,    3,   13, 1066,    1,  142, 1930,   30, 2169, 1997,\n",
      "           5, 2176,   10, 2538,   55,  722, 1778,   10,    5,  115, 2406, 1876,\n",
      "        1819,    1, 2117,    1,   54,    7, 2134, 3566, 3642,   13, 4104, 1232,\n",
      "          32, 1261, 1869,  216]), tensor([  13,   40, 2378, 2473,   56, 1567,    4,  475,   11,  333,   12,  747,\n",
      "          30,   40, 1706, 4540,    9, 2627, 4096, 1554,  915, 2636,  193, 4506,\n",
      "         264,    4, 3177,   14, 3016, 3035, 3999,   10, 4227, 1771, 3633,    4,\n",
      "           3, 3873,   16,  142,  142,  172, 3230,   59,   21, 3349,   11, 4009,\n",
      "         686, 1664,  511,    4,  285,   15, 1032,  119,  646, 4055, 1079,    1,\n",
      "          81, 3655,  148,   59,   13,   13,    5,  425,   61, 2909, 1399, 1158,\n",
      "        4477,   90,  142,   10, 3585, 1085,   61,   51,    5, 3850, 3227,  115,\n",
      "        1631,  142,   30, 3891,  395,  170,  994, 1673,   10, 2900,  154,   59,\n",
      "         142,   24, 3404,   13]), tensor([2446,   61,  418, 1273,   48,  216, 4434, 3196,  438,  857, 4603, 2932,\n",
      "        1743, 1903,    3, 2917, 3125,    1, 2809, 3108,   56,   81, 2493,    2,\n",
      "        3389, 4098, 1163,   52,   59,  107,  744,  524,   10,  658, 4317,   30,\n",
      "           3,  142, 1967, 1863, 1547, 4171,  113,  587,    4, 3702,  721,    7,\n",
      "         119,   54,   13, 4004,   24,   34,  108, 1864, 3416,    1, 1734,   13,\n",
      "          75, 2173, 3986,   13, 3572, 1636,    1,    3,  633,  770, 2502, 2135,\n",
      "        3781,    1, 1582,   36,  828, 1884,   95,  216, 2879, 1549,   13,  119,\n",
      "        2392,   20, 3441, 4397,    1,  120,  189, 3563,  657, 2751, 4005,    0,\n",
      "        1542, 1319, 2810,  546]), tensor([3633, 1048, 2227,  447,   61,    4, 1389, 3595,  503,    3,   14, 2821,\n",
      "         119, 4329, 4343, 2522,  101,  547,  538, 3462, 1779, 1238, 1374, 3434,\n",
      "         857, 1908,  142,   61, 3223, 3919, 2107,    1,   45,  883,  224,    3,\n",
      "           1, 1334, 1973,  119, 3053,   11, 1102, 1415, 1671, 3550, 4302, 1156,\n",
      "          55, 1011, 2811,   75,   10, 1519,    4, 1317, 1279, 1870, 2797,   28,\n",
      "        2581,   30,  677,  825,    5,    1,  266, 3525, 1804,    7,    0, 1395,\n",
      "           7, 2485,  145,   13,   75, 2056, 2935,  503, 2580,    5,   55, 3021,\n",
      "        4192, 1836,   10,    7,   59,  604,   13, 1458, 4405, 4144,    7, 1870,\n",
      "        2945, 1996,   52, 4330]), tensor([  31, 3815, 1049,  479, 3078, 1949, 3184, 3757,  503, 1415, 4442,   25,\n",
      "         182, 1519,   10,   13,   67,   13, 2914,   48, 4458,  881, 1503, 1113,\n",
      "         367,    2, 3989, 4097,  141, 3568,   68,   13, 4003, 2464, 1140, 3130,\n",
      "        3314, 3581,   10, 1611,   84, 3968,   13, 2445, 3772,   59, 1821, 3117,\n",
      "        4602,  533, 2549,    2,   75, 2235, 2689, 3830,  715, 4122, 4481, 1108,\n",
      "         668,  906,  115, 1822,  934, 3262, 2085,    7, 1107,    0, 2034, 1698,\n",
      "          48, 1706, 2752,    5,   13,  650,  418,    7,  946,  980,   13, 1380,\n",
      "        1512,   95, 1514,   63, 2924, 1452, 2890, 1728,  140, 4319, 1129, 2587,\n",
      "          24,   55,   50, 1712]), tensor([1976,   67, 3780,   30, 2414,  590,  991, 3306, 3071, 1544,  986, 3530,\n",
      "          13, 3872, 3089,   28, 1988,  119, 3562, 4609,  159, 1725, 2017, 3944,\n",
      "        1365,   65,    5,    6, 2739, 1591,   56,   56, 1546, 3801,  142, 4033,\n",
      "         427,    6,   13, 3004,   30, 3345, 2443, 1080, 2547, 2107, 2808, 2286,\n",
      "          54,    8,   25, 4283, 4358, 2961, 1886,    1, 1893, 1176,  357,    4,\n",
      "           3,   61, 1590, 1542,   90,    1, 1175,  141,   38, 3986, 1408, 1463,\n",
      "           5, 2713,  141,   13,  973,   59, 1418, 2571,   10,  661, 1197,   40,\n",
      "         824,  829,  776, 3160,   11,   90, 2496, 1196, 1810,  216,  836, 2834,\n",
      "        2309,  357,  163, 2395]), tensor([ 286, 3539, 2107, 4269, 2103, 3079,   31,   24, 4376,   51, 3279, 1118,\n",
      "           4, 3063,    1, 1762, 3729,   61,    0, 2192,   24, 2530,   73,   34,\n",
      "           7,   52, 2605, 1458, 4373,  179, 4095, 1820, 1877, 2438,  145,   11,\n",
      "          95, 3676, 4477,  700, 2315, 2578,  605,   75, 2098, 2416, 2109,    9,\n",
      "          56,   40, 2073, 2267, 4424, 4468,  142, 3355, 1667, 3443,   32,    9,\n",
      "         395,  311, 2437,    1, 4248,   10,   20,   55, 1084, 3204,  496, 2889,\n",
      "         797,  216, 4351, 1556, 1382,  764,  611,   68,    2, 2481,   19,   84,\n",
      "        2677,   10, 1927, 1071,  145,   73,   50, 1595, 4188, 2229, 4388, 2289,\n",
      "          30,   13, 3827,    3]), tensor([1856,   28,   25,   13, 3713, 1988,   51, 3761,   13,  391,   13,    1,\n",
      "        2350, 1727,   13,   13,  670,   40,  504, 3478, 3668, 2477, 1251,   48,\n",
      "        3262, 1861,   64, 2995, 3462,  141,  341,   13, 2764,    3, 1954, 4538,\n",
      "          54, 1849, 3624,  158,   10, 1145,    2,   13, 1444, 1236, 2564,    5,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        1150])] tensor([  90,   32, 2389,  ..., 2564,    5, 1150])\n",
      "batch 0 / 13\n",
      "batch 1 / 13\n",
      "batch 2 / 13\n",
      "batch 3 / 13\n",
      "batch 4 / 13\n",
      "batch 5 / 13\n",
      "batch 6 / 13\n",
      "batch 7 / 13\n",
      "batch 8 / 13\n",
      "batch 9 / 13\n",
      "batch 10 / 13\n",
      "batch 11 / 13\n",
      "batch 12 / 13\n",
      "[tensor([4178, 2386, 4400,   61, 3402, 2759,  116, 2289, 3322, 3121, 2887,  969,\n",
      "        3273, 3859, 1403,   36,  533,  279, 2869, 3958, 3798,  884, 2033, 2505,\n",
      "          38,  640, 4189, 1151, 1183, 1920, 2869, 1140, 3798,  395, 3798, 4283,\n",
      "        1348, 4067, 2994, 1838,  577,  486, 1985, 3798, 3076, 2282, 1889, 2377,\n",
      "        4143, 1500,   64, 4608, 3822, 1946, 4184, 1946, 3732, 3798,  775, 2490,\n",
      "        1805, 1662, 1120, 1995, 1823, 3798, 2363, 2987, 1081,   50,  914, 2147,\n",
      "         915, 1281,  722, 1747, 1719, 3632, 1347, 2503, 3799, 2775, 2632,  237,\n",
      "        1805, 3688,   41,   31,  279,  657,  643, 3922,  483,  279,  689, 2982,\n",
      "        4579, 4217,  747, 1675]), tensor([  76,  923, 1522, 4060, 3256, 4591,    7, 3615, 1773, 2204,   83,  986,\n",
      "        2314,  897,  513,  369,  790, 3818, 1987,  513, 1994,  242, 2728, 3479,\n",
      "        1893,  299,   95,  949,  135, 2349, 2260, 1960, 2994,  513,  884,  732,\n",
      "        3765, 4056,  726, 3822, 2805,   56, 1362, 3047, 1594, 3428, 1654,  323,\n",
      "        3436, 3901,  340,  747, 1074, 1903,   23, 3767,  878, 1193, 3712, 2386,\n",
      "        3250, 3798, 1222, 4178, 3901,  533,  113,  656, 1430,  284, 2910, 1721,\n",
      "         124,   19,  388, 3798,  997,  911, 2289, 2673,  897, 3892, 2879, 1988,\n",
      "        1304,  513,   26, 3139,  468, 2811, 3798,  884, 3757, 3681, 1631, 3234,\n",
      "        1481, 4358,  914,    2]), tensor([1681, 1893, 2825, 2386,  425, 2942, 3949, 2997,  884,   11,  293, 2951,\n",
      "        1675,  135, 2178,  237, 3645, 3329, 1426, 4342, 1077, 2363, 2282, 2503,\n",
      "        3043, 2887, 2192, 1415, 3087, 3798, 4037, 3564, 4573, 2762,  966, 2875,\n",
      "        2771, 2001,  140, 2681, 1403, 3798, 1742,  581, 1391, 1148,  726, 1637,\n",
      "        3799,  542, 1859, 2675, 1403, 1719,  703, 3125, 2505, 3645, 2181, 3970,\n",
      "        1403, 1953, 1719,  766,  211,  468, 1675,  644,   76, 4492, 1698,  693,\n",
      "         884, 3770,  380, 4409, 3233, 4223,   50, 2203, 2503, 4272, 2668, 3198,\n",
      "         237,   13,   77,  660, 3885, 1889, 3901, 1275, 2110,  884, 3825,  722,\n",
      "         130, 1793,   58,  406]), tensor([3767, 2282, 1719, 1042,  766,   31, 2431, 3798, 3798,  279,   42, 1841,\n",
      "         102, 2869, 2386, 3087,  884, 1058,  165,   10, 2260, 2363, 4137, 1585,\n",
      "         405, 2162, 4602,   45, 1966, 1222,  766, 2383, 3933,  284, 2321,  232,\n",
      "        3798, 2289, 3708,  451,   44,  503,   92, 2485,  251,  640,  358, 2147,\n",
      "        2903, 3433, 3082,  905,  279, 2503, 3087, 2363, 3139, 3994, 2892, 1168,\n",
      "        3428, 4595, 2651,   33,   29, 4375, 3733, 2517, 3570, 3798, 1347,  827,\n",
      "         146, 2283,   42, 3901,  172,  279, 2503, 4272,   22,  378, 2967, 3617,\n",
      "        4076, 3822,  424, 4175, 3047, 3176, 2481,  468,    9, 1946, 2356, 1464,\n",
      "        1485, 2386,  340, 4199]), tensor([1804, 2298, 3798, 2386, 3798, 1014,  726,  279, 3767, 2198, 2197, 2869,\n",
      "        2503, 4162,  120, 2852,   37, 1403,   43, 3217,  232,  396, 4016, 3087,\n",
      "        2677,  519,  722, 3087, 3936,  100, 3798, 3836, 4137,  884, 1883, 1353,\n",
      "        2775,  237,  442, 3417, 2333,  640, 3798, 2890, 3853, 3798, 3658, 3339,\n",
      "        1103, 1464, 3319, 2481, 2258, 4118, 4076, 3289,   85,  274,   31,  193,\n",
      "        1914, 3339, 1355,  884, 3798, 2614,  638, 4143, 2794, 2631, 2503,  468,\n",
      "        3639, 4210, 3139, 2503,  897, 2964,   70, 3720, 3398, 3486, 2934, 4492,\n",
      "         897, 4034,  884, 2757, 1294, 3296, 1946, 1154,  104, 1889, 3424,  134,\n",
      "         312,   48, 1120, 3798]), tensor([2398,  598, 3139,   60, 1631,  279, 1946, 2682,  640, 3798,  118, 4076,\n",
      "        1448, 2033, 1631, 1793, 3322, 1237, 1072, 4058,  125, 1396,  279,  878,\n",
      "         970, 3839, 4492,  897, 3339, 2481,  468, 1696, 3820, 2413,   19, 1863,\n",
      "        1403, 2191,   33, 1823,  279,  939, 3541, 4437, 4319, 4061,   31, 1309,\n",
      "        3481,  158,  766, 1990,  219, 1889, 1889,  722, 1439, 1436, 3453, 3636,\n",
      "         324, 3055,   73,  640, 3798, 3903, 1403, 1518,  360, 3339,   21, 1391,\n",
      "        2503, 1171,  884, 3042, 4076, 1540, 2286,  884, 2503,  722,  717, 2758,\n",
      "        1370, 1403, 1779,  468, 4272, 3632, 1236, 4602, 3468, 3798, 1842, 4444,\n",
      "        2386,  668,  391, 1889]), tensor([3798,  827,   29,  418, 2289, 1287,  279, 2497,    2, 1239, 3859,   40,\n",
      "        3339,  827,  716, 3967,  766, 4386, 2600, 1246, 3250, 1291, 2282, 4454,\n",
      "          27,  279, 3873, 1841,  982, 2251,  503,  884, 2289, 1691,   76, 2033,\n",
      "         640,   70, 1893, 1518, 3087,  143, 3812, 2481, 1465, 3886,  897, 3081,\n",
      "        3290, 2067,   75,  279, 3980, 3825,  465,  513, 3902,   98,   65,  468,\n",
      "         362,   86,  245, 2481, 3798, 3798, 2503, 1374, 1805, 4386, 2368,  500,\n",
      "        4046, 4178, 3087,  182, 1096, 2564, 1805,   31, 2503, 2279, 3568,  722,\n",
      "        2099, 1518, 3339, 2406,  576,   14,   17, 2498,  120,  241,   50, 3043,\n",
      "        1518, 2650, 3358, 3798]), tensor([3281, 1805,  976,  122, 2371, 1889,  347, 4610,  504, 1925, 4303, 1124,\n",
      "        4194,  159,  640, 3243, 3090, 1403,  129, 4009, 2289,  362,   34, 4143,\n",
      "        4482, 1415, 1691, 2903, 3043,   63, 2091,  417,  884, 1913, 3348, 3339,\n",
      "         640, 3087, 2117,   30,  239,   71,  329, 1429, 2033, 2922, 3681, 2578,\n",
      "         513, 2363, 3798, 3295, 2650,   63,  118,  919, 3081, 1403, 1998, 3798,\n",
      "         711, 3689, 3141, 3798, 3109, 4545,  468,  160,   67,   80, 4084, 1253,\n",
      "        3545,  468, 4188, 1081, 3535,   31,  237, 1889, 1610, 1418, 3798,  513,\n",
      "         265,   78, 4081, 4397, 1403,  387,  870, 2015,   16, 4261, 2805, 1415,\n",
      "         911, 2842, 1974, 2608]), tensor([  76,    8,  154,   20, 1805, 2033, 2770, 2517, 3047,  640,   13, 4142,\n",
      "         513, 2700, 4003, 2991,    2, 2732,  208, 2073,  144, 3774, 1987, 3954,\n",
      "        1759, 2435, 3087, 1805, 1452,   68, 4296,  468,   20, 2158,  496,  640,\n",
      "         468, 2420,   13,  513, 4188,  897, 1369, 1291, 1261, 2287, 3975,  120,\n",
      "        4076, 2285, 1829,  711,  884,   35,  110,  139, 3268, 1402, 3858, 4492,\n",
      "        1630, 3339, 1679,  887, 2503,  468, 1532, 1161,   24, 3632,  533, 2203,\n",
      "        3632, 2559, 2514, 3798,  711,  186, 2651, 3047,  692, 2503, 4076, 2504,\n",
      "        3075,   47, 3428, 3632, 3043,  313, 3798,  558,  966, 4348, 2578, 3301,\n",
      "        4514, 3403, 1793, 3856]), tensor([1203, 3909,  102,   18, 2522, 1784,  681, 3112, 3047,  462, 3770, 1799,\n",
      "          73,   35,  884, 1719,  483, 3798,  173, 2371, 4252,  618, 3886, 2020,\n",
      "        1061, 4143, 4091, 3770, 2869, 1765, 3417, 3798, 3992, 1369, 3041, 3255,\n",
      "        2219, 4594,  884,  147, 3901,  358, 2147, 1371, 3173, 2481,  562, 3559,\n",
      "        4467,   55, 3441, 4143,  711,  119,   55,  690,  361, 1127, 4241,   28,\n",
      "         243, 1003,  722, 3076, 1130, 3664, 1345,   18, 3729,  533,  236, 3679,\n",
      "        2371, 1193,  135, 2503, 2147, 2013,    8, 3932, 1075,  401, 3798,   51,\n",
      "        2126,  237,   10, 3767,  684,   91, 3019, 1809,  348, 3891, 1385, 4478,\n",
      "        2650, 4076, 3322,  486]), tensor([ 334,  483, 3505, 3339,  653,  400, 1771, 4496, 3194, 1341,   32, 3628,\n",
      "        2147, 2620, 1800, 4492, 3759,  513, 4607, 3660,    1,  663,  739, 2836,\n",
      "        4315,  299, 2503, 1946,   12, 1795, 2289, 2289,  205, 3213, 1518, 4032,\n",
      "         290, 1946, 3798, 3484, 3641, 3136,  101,  956, 3820,   58, 1524, 2396,\n",
      "        2363, 2605, 3075, 1959, 1440,  859,  664, 1403,  133, 2141,  177,  279,\n",
      "         640, 1805, 2232,  236, 4178, 1403, 4352, 2869, 1464, 3335, 3070, 2431,\n",
      "        2503, 2353, 2869, 3798, 2106, 3043, 1170, 2739,  884,  545, 3303, 1804,\n",
      "         279,  388, 3549,   51,  897, 4178, 2845,   23,   15, 1889,  544, 3398,\n",
      "         192,  428, 3964,  844]), tensor([1039, 3049, 1630, 3281,  100, 2543, 1203, 2650, 2957,   31, 3084, 2713,\n",
      "         279, 1151, 2724, 3269, 4067, 1805,  533, 3395, 2650,  458,  450, 1031,\n",
      "         599, 2903,   46,  989,  123, 1584,  371,    6, 2801,  171, 2514, 4531,\n",
      "         237, 2032, 3402, 1090,  895, 1491,   37,  711,  754, 1466, 2904,  766,\n",
      "        2289,  827, 3244, 3877, 3771, 2706, 1518, 2829, 3347, 4563, 2386,  766,\n",
      "        2428, 4444,  330,  468,   14, 3428, 2693, 4076,  489, 3065,  886,  243,\n",
      "        2303, 1378, 3144,   10, 1032,  499,   33, 3417, 4143, 3239, 2261, 3901,\n",
      "         116,  120,  172, 1452,  639,  450, 3322,   34, 1576, 1255, 1582, 1017,\n",
      "        3339, 1719,   85,  640]), tensor([3236, 4492, 3075, 3798, 4473,  323,   31, 2481,  844, 4375, 3798,  468,\n",
      "        2148, 1758, 3798, 3798,  813, 1804,  133,  267, 4515,  147, 3149, 2371,\n",
      "        3333, 1379,  879,   52, 1355, 2869,   39, 2147, 4098,  640,   39,   77,\n",
      "        4272, 3414,   33,   55, 3428, 1221, 4143, 1719, 1668, 1516,   86, 1090,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        4311])] tensor([4178, 2386, 4400,  ...,   86, 1090, 4311])\n",
      "MRR (raw): 0.023715\n",
      "Hits (raw) @ 1: 0.003603\n",
      "Hits (raw) @ 3: 0.019215\n",
      "Hits (raw) @ 10: 0.052442\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.023715466260910034"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_raw_mrr(embed, model.w_relation,torch.LongTensor(test_data),[1,3,10],100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4622,    3],\n",
       "        [4622,    1],\n",
       "        [1249,    5],\n",
       "        ...,\n",
       "        [1035,    6],\n",
       "        [4622,    1],\n",
       "        [1356,    4]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[:,:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
